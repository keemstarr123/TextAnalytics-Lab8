{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadae649-257a-4982-9688-f939c4702a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from tabulate import tabulate \n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4324974-de94-4b77-a88c-fa51be2ed5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"I love playing football on the weekends\", \n",
    "           \"I enjoy hiking and camping in the mountains\", \n",
    "           \"I like to read books and watch movies\", \n",
    "           \"I prefer playing video games over sports\", \n",
    "           \"I love listening to music and going to concerts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f668cfde-179a-4a19-82b9-17405285e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer() \n",
    "X = vectorizer.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f578d2-7a9f-44f1-a120-b049ab9afc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2  # Define the number of clusters \n",
    "km = KMeans(n_clusters=k) \n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fe8eaa-6fea-4ffd-a6ed-cddacf402484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            0\n",
      "I enjoy hiking and camping in the mountains                        1\n",
      "I like to read books and watch movies                              1\n",
      "I prefer playing video games over sports                           0\n",
      "I love listening to music and going to concerts                    0\n"
     ]
    }
   ],
   "source": [
    "# Predict the clusters for each document \n",
    "y_pred = km.predict(X) \n",
    " \n",
    "# Display the document and its predicted cluster in a table \n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]] \n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)]) \n",
    "print(tabulate(table_data, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fcc3c3-b720-4cde-870d-ab94a205e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " playing\n",
      "\n",
      " love\n",
      "\n",
      " to\n",
      "\n",
      " weekends\n",
      "\n",
      " on\n",
      "\n",
      " football\n",
      "\n",
      " video\n",
      "\n",
      " sports\n",
      "\n",
      " prefer\n",
      "\n",
      " over\n",
      "\n",
      "Cluster 1:\n",
      " and\n",
      "\n",
      " movies\n",
      "\n",
      " books\n",
      "\n",
      " camping\n",
      "\n",
      " enjoy\n",
      "\n",
      " hiking\n",
      "\n",
      " in\n",
      "\n",
      " like\n",
      "\n",
      " watch\n",
      "\n",
      " mountains\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top terms per cluster \n",
    "print(\"\\nTop terms per cluster:\") \n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "terms = vectorizer.get_feature_names_out() \n",
    "for i in range(k): \n",
    "    print(\"Cluster %d:\" % i) \n",
    "    for ind in order_centroids[i, :10]: \n",
    "        print(' %s' % terms[ind]) \n",
    "        print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ca381f-752b-4004-8a2d-16d9cc71d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity \n",
    "total_samples = len(y_pred) \n",
    "cluster_label_counts = [Counter(y_pred)] \n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples \n",
    "print(\"Purity:\", purity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee9d33c-4346-4aae-9fbc-70ca1c7f1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.cluster import KMeans \n",
    "from gensim.models import Word2Vec \n",
    "from tabulate import tabulate \n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a294442a-92fc-47c6-ac9a-16f71bae2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"I love playing football on the weekends\", \n",
    "           \"I enjoy hiking and camping in the mountains\", \n",
    "           \"I like to read books and watch movies\", \n",
    "           \"I prefer playing video games over sports\", \n",
    "           \"I love listening to music and going to concerts\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1710ed1-9a6c-40c6-ac85-3dd82451eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = [doc.split() for doc in dataset] \n",
    "word2vec_model = Word2Vec(sentences=tokenized_dataset, vector_size=100, \n",
    "window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76891690-e7a6-4d72-a27e-8748123119f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.mean([word2vec_model.wv[word] for word in doc.split() if word in \n",
    "word2vec_model.wv], axis=0) for doc in dataset]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c74df82-3698-4997-be0d-2102d3038f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            1\n",
      "I enjoy hiking and camping in the mountains                        1\n",
      "I like to read books and watch movies                              1\n",
      "I prefer playing video games over sports                           0\n",
      "I love listening to music and going to concerts                    1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 2  # Define the number of clusters \n",
    "km = KMeans(n_clusters=k) \n",
    "km.fit(X) \n",
    " \n",
    "# Predict the clusters for each document \n",
    "y_pred = km.predict(X) \n",
    " \n",
    "# Tabulate the document and predicted cluster \n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]] \n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)]) \n",
    "print(tabulate(table_data, headers=\"firstrow\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73dbce9-73a4-44bd-bac3-b7683373cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity \n",
    "total_samples = len(y_pred) \n",
    "cluster_label_counts = [Counter(y_pred)] \n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples \n",
    "print(\"Purity:\", purity) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4945e-ce45-433b-a0ba-9d734a0ce4ac",
   "metadata": {},
   "source": [
    "<h1>Exercise 1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "652c387b-2ae5-47a1-b677-9ba998b5f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\haoho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\haoho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\haoho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\haoho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\haoho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "import emoji \n",
    "import string \n",
    "import nltk \n",
    " \n",
    "from bs4 import BeautifulSoup \n",
    "from autocorrect import Speller \n",
    "from nltk.corpus import stopwords, wordnet \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag \n",
    " \n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')                    # For lemmatization \n",
    "nltk.download('omw-1.4')                     # WordNet lexical database \n",
    "nltk.download('averaged_perceptron_tagger_eng')  # For POS tagging \n",
    "nltk.download('punkt')                       # For tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01cc0315-e6ea-4fca-aa73-665b048937ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\haoho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "slang_dict = {\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bff\": \"best friend forever\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"wtf\": \"what the fuck\",\n",
    "    \"wth\": \"what the hell\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"ftw\": \"for the win\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"ama\": \"ask me anything\",\n",
    "    \"tldr\": \"too long didn't read\",\n",
    "    \"nsfw\": \"not safe for work\",\n",
    "    \"atm\": \"at the moment\",\n",
    "    \"bday\": \"birthday\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"rn\": \"right now\",\n",
    "    \"ty\": \"thank you\",\n",
    "    \"yw\": \"you're welcome\",\n",
    "    \"wbu\": \"what about you\",\n",
    "    \"wyd\": \"what are you doing\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"idc\": \"I don't care\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"sus\": \"suspicious\",\n",
    "    \"fr\": \"for real\",\n",
    "    \"cap\": \"lie\",\n",
    "    \"no cap\": \"no lie\",\n",
    "    \"salty\": \"bitter or upset\",\n",
    "    \"savage\": \"brutally honest or bold\",\n",
    "    \"based\": \"confident and unapologetically true\",\n",
    "    \"simp\": \"someone who does too much for someone they like\",\n",
    "    \"fam\": \"close friend or family\",\n",
    "    \"vibe\": \"a mood or atmosphere\",\n",
    "    \"mfw\": \"my face when\",\n",
    "    \"tfw\": \"that feeling when\",\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"fomo\": \"fear of missing out\",\n",
    "    \"bruh\": \"bro or seriously?\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"rip\": \"rest in peace\",\n",
    "    \"pog\": \"awesome or amazing moment\",\n",
    "    \"rizz\": \"charisma or charm, especially in flirting\",\n",
    "    \"delulu\": \"delusional\",\n",
    "    \"solulu\": \"solution\",\n",
    "    \"trululu\": \"truth\",\n",
    "    \"brain rot\": \"mental fatigue from consuming low-quality or excessive online content\",\n",
    "    \"let them cook\": \"encouragement to let someone continue their actions or ideas\",\n",
    "    \"yassified\": \"glamorized or made fabulous in an exaggerated way\",\n",
    "    \"mid\": \"mediocre or average\",\n",
    "    \"unhinged\": \"wild or chaotic behavior\",\n",
    "    \"lore\": \"background story or context\",\n",
    "    \"chat\": \"a group of people, often used to address an audience\",\n",
    "    \"yap\": \"to talk excessively or gossip\",\n",
    "    \"sigma\": \"a term describing a confident, independent person\",\n",
    "    \"gigachad\": \"an idealized, hyper-masculine man\",\n",
    "    \"baddie\": \"a confident and attractive woman\",\n",
    "    \"mewing\": \"a facial exercise technique aimed at improving jawline definition\",\n",
    "    \"beta maxing\": \"exhibiting submissive or non-dominant behavior\",\n",
    "    \"skibidi\": \"nonsensical term from a viral meme, often used humorously\",\n",
    "    \"gyatt\": \"exclamation of surprise or admiration\",\n",
    "    \"fanum tax\": \"stealing food from someone\",\n",
    "    \"bop\": \"a derogatory term used to shame individuals for perceived promiscuity\",\n",
    "    \"serving cunt\": \"exuding confidence and style in a bold, unapologetic manner\",\n",
    "    \"fujoing out\": \"obsessing over male-male fictional relationships\",\n",
    "    \"AI slop\": \"low-quality content generated by artificial intelligence\",\n",
    "    \"tim cheese\": \"a fictional meme character from a viral trend\",\n",
    "    \"vibe check\": \"assessing someone's mood or energy\",\n",
    "    \"main character energy\": \"behaving as if one is the protagonist of a story\",\n",
    "    \"clout\": \"influence or fame, especially on social media\",\n",
    "    \"ghosting\": \"suddenly cutting off communication without explanation\",\n",
    "    \"thirst trap\": \"a photo or post intended to attract attention\",\n",
    "    \"receipts\": \"evidence or proof, often in the form of screenshots\",\n",
    "    \"shadowban\": \"a stealth ban where a user's content is hidden without their knowledge\",\n",
    "    \"flex\": \"to show off\",\n",
    "    \"ratio\": \"a situation where replies to a post outnumber likes, indicating disapproval\",\n",
    "    \"thirsty\": \"desperate for attention\",\n",
    "    \"cheugy\": \"out of date or trying too hard\",\n",
    "    \"slay\": \"to excel or do something exceptionally well\",\n",
    "    \"extra\": \"over the top; dramatic\",\n",
    "    \"period\": \"emphasis on a statement; end of discussion\",\n",
    "    \"bet\": \"agreement or affirmation\",\n",
    "    \"cray\": \"crazy\",\n",
    "    \"pwn\": \"dominate or defeat\",\n",
    "    \"kda\": \"kill/death/assist ratio in gaming\",\n",
    "    \"rpg\": \"role-playing game\",\n",
    "    \"noob\": \"newbie or inexperienced person\",\n",
    "    \"goated\": \"exceptionally good; the best\",\n",
    "    \"drip\": \"stylish or fashionable\",\n",
    "    \"stan\": \"overzealous fan\",\n",
    "    \"snatched\": \"looking good or fashionable\",\n",
    "    \"lowkey\": \"slightly or secretly\",\n",
    "    \"highkey\": \"very or openly\",\n",
    "    \"fire\": \"excellent or amazing\",\n",
    "    \"lit\": \"exciting or excellent\",\n",
    "    \"suss\": \"suspicious\",\n",
    "    \"woke\": \"socially aware\",\n",
    "    \"karen\": \"entitled or demanding woman\",\n",
    "    \"chad\": \"confident and attractive man\",\n",
    "    \"yeet\": \"throw or discard forcefully\",\n",
    "    \"boomer\": \"older person\",\n",
    "    \"gen z\": \"generation born between mid-1990s and early 2010s\",\n",
    "    \"gen alpha\": \"generation born from early 2010s onwards\",\n",
    "    \"af\": \"as fuck\",\n",
    "    \"tf\": \"the fuck\",\n",
    "    \"tysm\": \"thank you so much\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"bbl\": \"be back later\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"ilysm\": \"I love you so much\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"nvm\": \"never mind\",\n",
    "    \"tmi\": \"too much information\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"that's tea\": \"that's gossip or the truth\",\n",
    "    \"aura\": \"unique vibe or energy someone gives off\"\n",
    "}\n",
    "slang_dict = {k.lower(): v for k, v in slang_dict.items()}\n",
    "spell = Speller(lang='en')\n",
    "nltk.download('stopwords') \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ab92c7d-6ff1-4415-acd5-dd2db6be4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def url_removal(text):\n",
    "    return re.sub(r'http\\S+|www\\S+', '', text)  \n",
    "\n",
    "def html_removal(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "def punctuation_special_character_removal(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def numbers_removal(text):\n",
    "    return re.sub(r\"\\d\", \"\", text)\n",
    "\n",
    "def emoji_removal(text):\n",
    "    return emoji.replace_emoji(text, replace=\"\")\n",
    "\n",
    "def internet_slang_replacement(text):\n",
    "    escaped_slang_words = []\n",
    "    for word in slang_dict.keys(): \n",
    "        escaped_word = re.escape(word)  # Ensure special characters are escaped \n",
    "        escaped_slang_words.append(escaped_word)  # Add to list \n",
    " \n",
    "    # Join the words using '|' \n",
    "    slang_pattern = r'\\b(' + '|'.join(escaped_slang_words) + r')\\b' \n",
    " \n",
    "    # Define a replacement function \n",
    "    def replace_match(match): \n",
    "        slang_word = match.group(0).lower()  # Extract matched slang word \n",
    "        return slang_dict.get(slang_word, slang_word)   \n",
    " \n",
    "    # Use regex to replace slang words with full forms \n",
    "    replaced_text = re.sub(slang_pattern, replace_match, text, flags=re.IGNORECASE) \n",
    " \n",
    "    return replaced_text \n",
    "\n",
    "def spelling_correction(text):\n",
    "    return spell(text)\n",
    "\n",
    "def standardizing_cleaning_pipeline(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = lower_case(text)\n",
    "    text = url_removal(text)\n",
    "    text = html_removal(text)\n",
    "    text = emoji_removal(text)\n",
    "    text = internet_slang_replacement(text)\n",
    "    text = punctuation_special_character_removal(text)\n",
    "    text = numbers_removal(text)\n",
    "    text = spelling_correction(text)\n",
    "    return text\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = standardizing_cleaning_pipeline(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72a365fe-7f1e-498e-b10b-0e3c01a8b9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love playing football on the weekends',\n",
       " 'i enjoy hiking and camping in the mountains',\n",
       " 'i like to read books and watch movies',\n",
       " 'i prefer playing video games over sports',\n",
       " 'i love listening to music and going to concerts']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bdb52a4-ebf3-40e0-9446-75c3e4ea8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text): \n",
    "    words = text.split()   \n",
    "    filtered_words = [] \n",
    "    for word in words:  \n",
    "        lower_word = word.lower() \n",
    "        if lower_word not in stop_words: \n",
    "            filtered_words.append(word) \n",
    "    return \" \".join(filtered_words) \n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = remove_stopwords(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dca4c59-6bc3-44fe-9c3c-c3f121dddc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love playing football weekends',\n",
       " 'enjoy hiking camping mountains',\n",
       " 'like read books watch movies',\n",
       " 'prefer playing video games sports',\n",
       " 'love listening music going concerts']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12e947b1-c678-4aad-a329-d97b71482f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love play footbal weekend',\n",
       " 'enjoy hike camp mountain',\n",
       " 'like read book watch movi',\n",
       " 'prefer play video game sport',\n",
       " 'love listen music go concert']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def stem_text(text): \n",
    "    if not isinstance(text, str): \n",
    "        return \"\" \n",
    "    \n",
    "    words = text.split() \n",
    "    stemmed_words = [stemmer.stem(word) for word in words]  # Apply stemming \n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "def get_wordnet_pos(nltk_tag): \n",
    "    if nltk_tag.startswith('J'):  # Adjective \n",
    "        return wordnet.ADJ \n",
    "    elif nltk_tag.startswith('V'):  # Verb \n",
    "        return wordnet.VERB \n",
    "    elif nltk_tag.startswith('N'):  # Noun \n",
    "        return wordnet.NOUN \n",
    "    elif nltk_tag.startswith('R'):  # Adverb \n",
    "        return wordnet.ADV \n",
    "    else: \n",
    "        return wordnet.NOUN  # Default to noun \n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):  # Ensure input is a string \n",
    "       return \"\" \n",
    " \n",
    "    words = word_tokenize(text) \n",
    "    pos_tags = pos_tag(words)  \n",
    "     \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return \" \".join(lemmatized_words) \n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = stem_text(dataset[i])\n",
    "    dataset[i] = lemmatize_text(dataset[i])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c3050cf-5cc8-4b34-a476-79fb2fad1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = dataset.copy()\n",
    "vectorizer = TfidfVectorizer() \n",
    "X = vectorizer.fit_transform(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e635e29-9c96-4e49-a95b-206c526a7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.mean([word2vec_model.wv[word] for word in doc.split() if word in \n",
    "word2vec_model.wv], axis=0) for doc in dataset2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57c953f6-f1fe-4c54-8ffb-d688c504128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                        Predicted Cluster\n",
      "----------------------------  -------------------\n",
      "love play footbal weekend                       0\n",
      "enjoy hike camp mountain                        1\n",
      "like read book watch movi                       1\n",
      "prefer play video game sport                    1\n",
      "love listen music go concert                    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 2  # Define the number of clusters \n",
    "km = KMeans(n_clusters=k) \n",
    "km.fit(X) \n",
    " \n",
    "# Predict the clusters for each document \n",
    "y_pred = km.predict(X) \n",
    " \n",
    "# Tabulate the document and predicted cluster \n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]] \n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset2, y_pred)]) \n",
    "print(tabulate(table_data, headers=\"firstrow\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08c97f80-d473-4049-90c0-2fb5ae3644fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity \n",
    "total_samples = len(y_pred) \n",
    "cluster_label_counts = [Counter(y_pred)] \n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples \n",
    "print(\"Purity:\", purity) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d185489-935c-427a-99c0-1838411eac69",
   "metadata": {},
   "source": [
    "<h2>The purity is still the same after preprocessing for tfidf</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a1f9b0d-7d84-4f29-a6e1-8952618dce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = [doc.split() for doc in dataset] \n",
    "word2vec_model = Word2Vec(sentences=tokenized_dataset, vector_size=100, \n",
    "window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddb21a51-287e-46f6-84b3-b45415e2ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.mean([word2vec_model.wv[word] for word in doc.split() if word in \n",
    "word2vec_model.wv], axis=0) for doc in dataset]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8495699-82b6-41a1-941c-899383c1f70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                        Predicted Cluster\n",
      "----------------------------  -------------------\n",
      "love play footbal weekend                       1\n",
      "enjoy hike camp mountain                        0\n",
      "like read book watch movi                       1\n",
      "prefer play video game sport                    1\n",
      "love listen music go concert                    1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 2  # Define the number of clusters \n",
    "km = KMeans(n_clusters=k) \n",
    "km.fit(X) \n",
    " \n",
    "# Predict the clusters for each document \n",
    "y_pred = km.predict(X) \n",
    " \n",
    "# Tabulate the document and predicted cluster \n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]] \n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)]) \n",
    "print(tabulate(table_data, headers=\"firstrow\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81e038e8-f54e-41fb-9f6b-1d7d292ca348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity \n",
    "total_samples = len(y_pred) \n",
    "cluster_label_counts = [Counter(y_pred)] \n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples \n",
    "print(\"Purity:\", purity) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cd855-b806-4f60-b741-1887fa49d317",
   "metadata": {},
   "source": [
    "<h2>No changes for Word2Vector as well</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65effec-76f2-46b4-a74e-9ec954a669e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
